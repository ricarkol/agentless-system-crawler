#!/usr/bin/env python

'''
@author: Nilton Bila
@author  Sastry Duri, adopted for vulnerability annotator for kafka listening interface
(c) IBM Research 2015
'''

import argparse
import csv
import datetime
import logging
import signal
import sys
from cStringIO import StringIO

try:
    import simplejson as json
except:
    import json
    
from kafka import SimpleProducer, KafkaClient, KafkaConsumer

import frame_annotator

logger_name = "vulnerability-annotator.log"
class KafkaInterface(object):
    def __init__(self, kafka_url, logger, receive_topic, publish_topic, notify_topic):
        self.logger        = logger
        self.kafka_url     = kafka_url
        self.kafka         = KafkaClient(kafka_url)
        self.publish_topic = publish_topic
        self.receive_topic = receive_topic
        self.notify_topic = notify_topic
        
        self.kafka.ensure_topic_exists(receive_topic)
        self.kafka.ensure_topic_exists(publish_topic)
        self.kafka.ensure_topic_exists(self.notify_topic)
    
    def next_frame(self):
        consumer = KafkaConsumer(self.receive_topic, 
                                 group_id="compliance-annotator",
                                 metadata_broker_list=[self.kafka_url],
                                 fetch_message_max_bytes=512*1024*1024
                                 )
        for message in consumer:
            yield message.value
    
    def _publish(self, topic, data):
        producer = SimpleProducer(self.kafka)
        ret = producer.send_messages(topic, data)
        producer.stop()
        if ret:
            self.logger.debug("Published offset %s: %s" % (ret[0].offset, ret[0].error))

    def publish(self, data):
        self._publish(self.publish_topic, data)

    def notify(self, data):
        self._publish(self.notify_topic, data)


def sigterm_handler(signum=None, frame=None):
    print 'Received SIGTERM signal. Goodbye!'
    sys.exit(0)
signal.signal(signal.SIGTERM, sigterm_handler)
    
def process_message(kafka_url, logger, receive_topic, publish_topic, notify_topic):
    
    client = KafkaInterface(kafka_url, logger, receive_topic, publish_topic, notify_topic)
    annotator = frame_annotator.MakeScan()
    
    while True:
        try:
            for data in client.next_frame():
                packages = []
                files = []
                configs = []
                osinfo = None
                stream = StringIO(data)
                csv.field_size_limit(sys.maxsize) # required to handle large value strings
                csv_reader = csv.reader(stream, delimiter='\t', quotechar="'")
                metadata = None
                for ftype, fkey, fvalue in csv_reader:
                    if ftype == 'package':
                        packages.append(json.loads(fvalue))
                    if ftype == 'file':
                        files.append(json.loads(fvalue))
                    if ftype == 'config':
                        configs.append(json.loads(fvalue))
                    if ftype == 'os':
                        osinfo=json.loads(fvalue)
                    if not metadata and ftype == 'metadata':
                        metadata = json.loads(fvalue)
                stream.close()

                namespace = metadata['namespace']
                timestamp = metadata['timestamp']

                notification_msg = { 
                    'processor': 'compliance_annotator',
                    'status': 'start',
                    'namespace': namespace,
                    'timestamp': datetime.datetime.now().isoformat()
                }

                msg = json.dumps(notification_msg)
                logger.info(msg)
                client.notify(msg)
                vulnerabilities = annotator.makeScanForNamespace(namespace, timestamp, osinfo, packages)
        
                if vulnerabilities:
                    for vuln in vulnerabilities:
                        client.publish(json.dumps(vuln))
                    
                notification_msg['status'] = 'completed'
                notification_msg['timestamp'] = datetime.datetime.now().isoformat()

                msg = json.dumps(notification_msg)
                client.notify(msg)
                logger.info(msg)
        except Exception, e:
            logger.exception(e)
            logger.error("Uncaught exception: %s" % e)


if __name__ == '__main__':
    format = '%(asctime)s %(levelname)s %(lineno)s %(funcName)s: %(message)s'
    logging.basicConfig(filename="volnerability-annotator.log", filemode='w', format=format, level=logging.INFO)
    
    logger = logging.getLogger(logger_name)
    
    sh = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter(format)
    sh.setFormatter(formatter)
    logger.addHandler(sh)

    try:
        parser = argparse.ArgumentParser(description="")
        parser.add_argument('--kafka-url',  type=str, required=True, help='kafka url: host:port')
        parser.add_argument('--receive-topic', type=str, required=True, help='receive-topic')
        parser.add_argument('--notification-topic', type=str, required=True, help='topic to send process notification')
        parser.add_argument('--annotation-topic', type=str, required=True, help='topic to send annotations')
        args = parser.parse_args()
    
        process_message(args.kafka_url, logger, args.receive_topic, args.annotation_topic, args.notification_topic)
    except Exception, e:
        print('Error: %s' % str(e))
        logger.exception(e) 


